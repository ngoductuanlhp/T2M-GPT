{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.argv = ['']\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"  # specify which GPU(s) to be used\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from os.path import join as pjoin\n",
    "from torch.distributions import Categorical\n",
    "import json\n",
    "import clip\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "import options.option_transformer as option_trans\n",
    "import models.vqvae as vqvae\n",
    "import utils.utils_model as utils_model\n",
    "import utils.eval_trans as eval_trans\n",
    "from dataset import dataset_TM_train\n",
    "from dataset import dataset_TM_eval\n",
    "from dataset import dataset_tokenize\n",
    "import models.t2m_trans as trans\n",
    "from models.t2m_trans import uniform, cosine_schedule\n",
    "from options.get_eval_option import get_opt\n",
    "from models.evaluator_wrapper import EvaluatorModelWrapper\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-03 11:58:54,845 INFO {\n",
      "    \"batch_size\": 128,\n",
      "    \"block_size\": 25,\n",
      "    \"clip_dim\": 512,\n",
      "    \"code_dim\": 512,\n",
      "    \"dataname\": \"t2m\",\n",
      "    \"decay_option\": \"all\",\n",
      "    \"depth\": 3,\n",
      "    \"dilation_growth_rate\": 3,\n",
      "    \"down_t\": 3,\n",
      "    \"drop_out_rate\": 0.1,\n",
      "    \"embed_dim_gpt\": 512,\n",
      "    \"eval_iter\": 5000,\n",
      "    \"exp_name\": \"exp_debug\",\n",
      "    \"ff_rate\": 4,\n",
      "    \"fps\": [\n",
      "        20\n",
      "    ],\n",
      "    \"gamma\": 0.05,\n",
      "    \"if_maxtest\": false,\n",
      "    \"lr\": 0.0002,\n",
      "    \"lr_scheduler\": [\n",
      "        60000\n",
      "    ],\n",
      "    \"mu\": 0.99,\n",
      "    \"n_head_gpt\": 8,\n",
      "    \"nb_code\": 512,\n",
      "    \"num_layers\": 2,\n",
      "    \"optimizer\": \"adamw\",\n",
      "    \"out_dir\": \"output_GPT_Final/exp_debug\",\n",
      "    \"output_emb_width\": 512,\n",
      "    \"pkeep\": 1.0,\n",
      "    \"print_iter\": 50,\n",
      "    \"quantbeta\": 1.0,\n",
      "    \"quantizer\": \"ema_reset\",\n",
      "    \"resume_pth\": null,\n",
      "    \"resume_trans\": null,\n",
      "    \"seed\": 123,\n",
      "    \"seq_len\": 64,\n",
      "    \"split\": \"train\",\n",
      "    \"stride_t\": 2,\n",
      "    \"total_iter\": 100000,\n",
      "    \"vq_act\": \"relu\",\n",
      "    \"vq_dir\": \"./dataset/HumanML3D/exp_debug\",\n",
      "    \"vq_name\": \"exp_debug\",\n",
      "    \"warm_up_iter\": 1000,\n",
      "    \"weight_decay\": 1e-06,\n",
      "    \"width\": 512\n",
      "}\n",
      "2023-10-03 11:58:54,845 INFO {\n",
      "    \"batch_size\": 128,\n",
      "    \"block_size\": 25,\n",
      "    \"clip_dim\": 512,\n",
      "    \"code_dim\": 512,\n",
      "    \"dataname\": \"t2m\",\n",
      "    \"decay_option\": \"all\",\n",
      "    \"depth\": 3,\n",
      "    \"dilation_growth_rate\": 3,\n",
      "    \"down_t\": 3,\n",
      "    \"drop_out_rate\": 0.1,\n",
      "    \"embed_dim_gpt\": 512,\n",
      "    \"eval_iter\": 5000,\n",
      "    \"exp_name\": \"exp_debug\",\n",
      "    \"ff_rate\": 4,\n",
      "    \"fps\": [\n",
      "        20\n",
      "    ],\n",
      "    \"gamma\": 0.05,\n",
      "    \"if_maxtest\": false,\n",
      "    \"lr\": 0.0002,\n",
      "    \"lr_scheduler\": [\n",
      "        60000\n",
      "    ],\n",
      "    \"mu\": 0.99,\n",
      "    \"n_head_gpt\": 8,\n",
      "    \"nb_code\": 512,\n",
      "    \"num_layers\": 2,\n",
      "    \"optimizer\": \"adamw\",\n",
      "    \"out_dir\": \"output_GPT_Final/exp_debug\",\n",
      "    \"output_emb_width\": 512,\n",
      "    \"pkeep\": 1.0,\n",
      "    \"print_iter\": 50,\n",
      "    \"quantbeta\": 1.0,\n",
      "    \"quantizer\": \"ema_reset\",\n",
      "    \"resume_pth\": null,\n",
      "    \"resume_trans\": null,\n",
      "    \"seed\": 123,\n",
      "    \"seq_len\": 64,\n",
      "    \"split\": \"train\",\n",
      "    \"stride_t\": 2,\n",
      "    \"total_iter\": 100000,\n",
      "    \"vq_act\": \"relu\",\n",
      "    \"vq_dir\": \"./dataset/HumanML3D/exp_debug\",\n",
      "    \"vq_name\": \"exp_debug\",\n",
      "    \"warm_up_iter\": 1000,\n",
      "    \"weight_decay\": 1e-06,\n",
      "    \"width\": 512\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1460/1460 [00:03<00:00, 435.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointer Pointing at 0\n",
      "Reading checkpoints/t2m/Comp_v6_KLD005/opt.txt\n",
      "Loading Evaluation Model Wrapper (Epoch 28) Completed!!\n"
     ]
    }
   ],
   "source": [
    "##### ---- Exp dirs ---- #####\n",
    "args = option_trans.get_args_parser()\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "args.out_dir = os.path.join(args.out_dir, f'{args.exp_name}')\n",
    "args.vq_dir= os.path.join(\"./dataset/KIT-ML\" if args.dataname == 'kit' else \"./dataset/HumanML3D\", f'{args.vq_name}')\n",
    "os.makedirs(args.out_dir, exist_ok = True)\n",
    "os.makedirs(args.vq_dir, exist_ok = True)\n",
    "\n",
    "##### ---- Logger ---- #####\n",
    "logger = utils_model.get_logger(args.out_dir)\n",
    "writer = SummaryWriter(args.out_dir)\n",
    "logger.info(json.dumps(vars(args), indent=4, sort_keys=True))\n",
    "\n",
    "\n",
    "from utils.word_vectorizer import WordVectorizer\n",
    "w_vectorizer = WordVectorizer('./glove', 'our_vab')\n",
    "val_loader = dataset_TM_eval.DATALoader(args.dataname, False, 32, w_vectorizer)\n",
    "\n",
    "dataset_opt_path = 'checkpoints/kit/Comp_v6_KLD005/opt.txt' if args.dataname == 'kit' else 'checkpoints/t2m/Comp_v6_KLD005/opt.txt'\n",
    "\n",
    "wrapper_opt = get_opt(dataset_opt_path, torch.device('cuda'))\n",
    "eval_wrapper = EvaluatorModelWrapper(wrapper_opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint from pretrained/VQVAE/net_last.pth\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/mogen/lib/python3.9/site-packages/torch/serialization.py:308\u001b[0m, in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     f\u001b[39m.\u001b[39;49mseek(f\u001b[39m.\u001b[39mtell())\n\u001b[1;32m    309\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/tuan/tdngo/motion_ws/T2M-GPT/GPT_eval.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneghvar.cs.umass.edu/home/tuan/tdngo/motion_ws/T2M-GPT/GPT_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m trans_encoder \u001b[39m=\u001b[39m trans\u001b[39m.\u001b[39mText2Motion_Transformer(num_vq\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mnb_code, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneghvar.cs.umass.edu/home/tuan/tdngo/motion_ws/T2M-GPT/GPT_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m                                 embed_dim\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39membed_dim_gpt, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneghvar.cs.umass.edu/home/tuan/tdngo/motion_ws/T2M-GPT/GPT_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m                                 clip_dim\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mclip_dim, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneghvar.cs.umass.edu/home/tuan/tdngo/motion_ws/T2M-GPT/GPT_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m                                 drop_out_rate\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mdrop_out_rate, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneghvar.cs.umass.edu/home/tuan/tdngo/motion_ws/T2M-GPT/GPT_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m                                 fc_rate\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mff_rate)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneghvar.cs.umass.edu/home/tuan/tdngo/motion_ws/T2M-GPT/GPT_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mloading checkpoint from \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m'\u001b[39m\u001b[39mpretrained/VQVAE/net_last.pth\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bneghvar.cs.umass.edu/home/tuan/tdngo/motion_ws/T2M-GPT/GPT_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m ckpt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(args\u001b[39m.\u001b[39;49mresume_pth, map_location\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneghvar.cs.umass.edu/home/tuan/tdngo/motion_ws/T2M-GPT/GPT_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m net\u001b[39m.\u001b[39mload_state_dict(ckpt[\u001b[39m'\u001b[39m\u001b[39mnet\u001b[39m\u001b[39m'\u001b[39m], strict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bneghvar.cs.umass.edu/home/tuan/tdngo/motion_ws/T2M-GPT/GPT_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m net\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/miniconda3/envs/mogen/lib/python3.9/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/mogen/lib/python3.9/site-packages/torch/serialization.py:235\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[39mreturn\u001b[39;00m _open_buffer_writer(name_or_buffer)\n\u001b[1;32m    234\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m--> 235\u001b[0m     \u001b[39mreturn\u001b[39;00m _open_buffer_reader(name_or_buffer)\n\u001b[1;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in mode but got \u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mogen/lib/python3.9/site-packages/torch/serialization.py:220\u001b[0m, in \u001b[0;36m_open_buffer_reader.__init__\u001b[0;34m(self, buffer)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, buffer):\n\u001b[1;32m    219\u001b[0m     \u001b[39msuper\u001b[39m(_open_buffer_reader, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(buffer)\n\u001b[0;32m--> 220\u001b[0m     _check_seekable(buffer)\n",
      "File \u001b[0;32m~/miniconda3/envs/mogen/lib/python3.9/site-packages/torch/serialization.py:311\u001b[0m, in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m (io\u001b[39m.\u001b[39mUnsupportedOperation, \u001b[39mAttributeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 311\u001b[0m     raise_err_msg([\u001b[39m\"\u001b[39;49m\u001b[39mseek\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtell\u001b[39;49m\u001b[39m\"\u001b[39;49m], e)\n\u001b[1;32m    312\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mogen/lib/python3.9/site-packages/torch/serialization.py:304\u001b[0m, in \u001b[0;36m_check_seekable.<locals>.raise_err_msg\u001b[0;34m(patterns, e)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[39mif\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n\u001b[1;32m    301\u001b[0m         msg \u001b[39m=\u001b[39m (\u001b[39mstr\u001b[39m(e) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m. You can only torch.load from a file that is seekable.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m Please pre-load the data into a buffer like io.BytesIO and\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m try to load from it instead.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 304\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(msg)\n\u001b[1;32m    305\u001b[0m \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead."
     ]
    }
   ],
   "source": [
    "\n",
    "##### ---- Network ---- #####\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=torch.device('cuda'), jit=False)  # Must set jit=False for training\n",
    "clip.model.convert_weights(clip_model)  # Actually this line is unnecessary since clip by default already on float16\n",
    "clip_model.eval()\n",
    "for p in clip_model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "net = vqvae.HumanVQVAE(args, ## use args to define different parameters in different quantizers\n",
    "                       args.nb_code,\n",
    "                       args.code_dim,\n",
    "                       args.output_emb_width,\n",
    "                       args.down_t,\n",
    "                       args.stride_t,\n",
    "                       args.width,\n",
    "                       args.depth,\n",
    "                       args.dilation_growth_rate)\n",
    "\n",
    "\n",
    "trans_encoder = trans.Text2Motion_Transformer(num_vq=args.nb_code, \n",
    "                                embed_dim=args.embed_dim_gpt, \n",
    "                                clip_dim=args.clip_dim, \n",
    "                                block_size=args.block_size, \n",
    "                                num_layers=args.num_layers, \n",
    "                                n_head=args.n_head_gpt, \n",
    "                                drop_out_rate=args.drop_out_rate, \n",
    "                                fc_rate=args.ff_rate)\n",
    "\n",
    "\n",
    "print ('loading checkpoint from {}'.format('pretrained/VQVAE/net_last.pth'))\n",
    "ckpt = torch.load('pretrained/VQVAE/net_last.pth', map_location='cpu')\n",
    "net.load_state_dict(ckpt['net'], strict=True)\n",
    "net.eval()\n",
    "net.cuda()\n",
    "\n",
    "if args.resume_trans is not None:\n",
    "    print ('loading transformer checkpoint from {}'.format('output/GPT_MaskGit_fixbug_mask/net_last.pth'))\n",
    "    ckpt = torch.load('output/GPT_MaskGit_fixbug_mask/net_last.pth', map_location='cpu')\n",
    "    trans_encoder.load_state_dict(ckpt['trans'], strict=True)\n",
    "trans_encoder.eval()\n",
    "trans_encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fid=1000\n",
    "best_iter=0\n",
    "best_div=100\n",
    "best_top1=0\n",
    "best_top2=0\n",
    "best_top3=0\n",
    "best_matching=100\n",
    "nb_iter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fid, best_iter, best_div, best_top1, best_top2, best_top3, best_matching, writer, logger = \\\n",
    "    eval_trans.evaluation_transformer(\n",
    "        args.out_dir, val_loader, net, trans_encoder, logger, writer, nb_iter, best_fid, best_iter, best_div, best_top1, best_top2, best_top3, best_matching, clip_model=clip_model, eval_wrapper=eval_wrapper\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
