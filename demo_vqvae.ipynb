{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"  # specify which GPU(s) to be used\n",
    "\n",
    "import sys\n",
    "sys.argv = ['GPT_eval_multi.py']\n",
    "import options.option_transformer as option_trans\n",
    "args = option_trans.get_args_parser()\n",
    "\n",
    "args.dataname = 't2m'\n",
    "args.resume_pth = 'pretrained/VQVAE/net_last.pth'\n",
    "args.resume_trans = 'pretrained/VQTransformer_corruption05/net_best_fid.pth'\n",
    "args.down_t = 2\n",
    "args.depth = 3\n",
    "args.block_size = 51\n",
    "import clip\n",
    "import torch\n",
    "import numpy as np\n",
    "import models.vqvae as vqvae\n",
    "import models.t2m_trans as trans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils.motion_process import recover_from_ric, recover_from_rot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.skeleton import Skeleton\n",
    "from utils.paramUtil import *\n",
    "import visualization.plot_3d_global as plot_3d\n",
    "\n",
    "skeleton = Skeleton(offset=torch.from_numpy(t2m_raw_offsets), \n",
    "                    kinematic_tree=t2m_kinematic_chain,\n",
    "                    device='cuda')\n",
    "skeleton.set_offset(torch.from_numpy(t2m_raw_offsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs as cs\n",
    "\n",
    "split_file = os.path.join('dataset/HumanML3D/val.txt')\n",
    "joints_num = 22\n",
    "\n",
    "data_dict = {}\n",
    "id_list = []\n",
    "with cs.open(split_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        id_list.append(line.strip())\n",
    "\n",
    "\n",
    "mean = torch.from_numpy(np.load('./checkpoints/t2m/VQVAEV3_CB1024_CMT_H1024_NRES3/meta/mean.npy')).cuda()\n",
    "std = torch.from_numpy(np.load('./checkpoints/t2m/VQVAEV3_CB1024_CMT_H1024_NRES3/meta/std.npy')).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint from pretrained/VQVAE/net_last.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HumanVQVAE(\n",
       "  (vqvae): VQVAE_251(\n",
       "    (encoder): Encoder(\n",
       "      (model): Sequential(\n",
       "        (0): Conv1d(263, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "          (1): Resnet1D(\n",
       "            (model): Sequential(\n",
       "              (0): ResConv1DBlock(\n",
       "                (norm1): Identity()\n",
       "                (norm2): Identity()\n",
       "                (activation1): ReLU()\n",
       "                (activation2): ReLU()\n",
       "                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,))\n",
       "                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "              (1): ResConv1DBlock(\n",
       "                (norm1): Identity()\n",
       "                (norm2): Identity()\n",
       "                (activation1): ReLU()\n",
       "                (activation2): ReLU()\n",
       "                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "              (2): ResConv1DBlock(\n",
       "                (norm1): Identity()\n",
       "                (norm2): Identity()\n",
       "                (activation1): ReLU()\n",
       "                (activation2): ReLU()\n",
       "                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "          (1): Resnet1D(\n",
       "            (model): Sequential(\n",
       "              (0): ResConv1DBlock(\n",
       "                (norm1): Identity()\n",
       "                (norm2): Identity()\n",
       "                (activation1): ReLU()\n",
       "                (activation2): ReLU()\n",
       "                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,))\n",
       "                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "              (1): ResConv1DBlock(\n",
       "                (norm1): Identity()\n",
       "                (norm2): Identity()\n",
       "                (activation1): ReLU()\n",
       "                (activation2): ReLU()\n",
       "                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "              (2): ResConv1DBlock(\n",
       "                (norm1): Identity()\n",
       "                (norm2): Identity()\n",
       "                (activation1): ReLU()\n",
       "                (activation2): ReLU()\n",
       "                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (model): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): Sequential(\n",
       "          (0): Resnet1D(\n",
       "            (model): Sequential(\n",
       "              (0): ResConv1DBlock(\n",
       "                (norm1): Identity()\n",
       "                (norm2): Identity()\n",
       "                (activation1): ReLU()\n",
       "                (activation2): ReLU()\n",
       "                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,))\n",
       "                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "              (1): ResConv1DBlock(\n",
       "                (norm1): Identity()\n",
       "                (norm2): Identity()\n",
       "                (activation1): ReLU()\n",
       "                (activation2): ReLU()\n",
       "                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "              (2): ResConv1DBlock(\n",
       "                (norm1): Identity()\n",
       "                (norm2): Identity()\n",
       "                (activation1): ReLU()\n",
       "                (activation2): ReLU()\n",
       "                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Resnet1D(\n",
       "            (model): Sequential(\n",
       "              (0): ResConv1DBlock(\n",
       "                (norm1): Identity()\n",
       "                (norm2): Identity()\n",
       "                (activation1): ReLU()\n",
       "                (activation2): ReLU()\n",
       "                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,))\n",
       "                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "              (1): ResConv1DBlock(\n",
       "                (norm1): Identity()\n",
       "                (norm2): Identity()\n",
       "                (activation1): ReLU()\n",
       "                (activation2): ReLU()\n",
       "                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "              (2): ResConv1DBlock(\n",
       "                (norm1): Identity()\n",
       "                (norm2): Identity()\n",
       "                (activation1): ReLU()\n",
       "                (activation2): ReLU()\n",
       "                (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "                (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "        (4): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (5): ReLU()\n",
       "        (6): Conv1d(512, 263, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      )\n",
       "    )\n",
       "    (quantizer): QuantizeEMAReset()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = vqvae.HumanVQVAE(args, ## use args to define different parameters in different quantizers\n",
    "                       args.nb_code,\n",
    "                       args.code_dim,\n",
    "                       args.output_emb_width,\n",
    "                       args.down_t,\n",
    "                       args.stride_t,\n",
    "                       args.width,\n",
    "                       args.depth,\n",
    "                       args.dilation_growth_rate)\n",
    "\n",
    "print ('loading checkpoint from {}'.format(args.resume_pth))\n",
    "ckpt = torch.load(args.resume_pth, map_location='cpu')\n",
    "net.load_state_dict(ckpt['net'], strict=True)\n",
    "net.eval()\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = np.load(os.path.join('dataset/HumanML3D/new_joint_vecs', id_list[37] + '.npy'))\n",
    "\n",
    "motion = torch.from_numpy(motion).cuda()\n",
    "motion = (motion - mean) / std\n",
    "\n",
    "motion = motion[None, ...]\n",
    "# motion = motion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pose, loss_commit, perplexity = net(motion[0:0+1, :])\n",
    "pred_pose = pred_pose.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = recover_from_rot((motion*std+mean).float(), 22, skeleton)\n",
    "xyz = xyz.reshape(1, -1, 22, 3)\n",
    "xyz = xyz / 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_xyz = recover_from_rot((pred_pose*std+mean).float(), 22, skeleton)\n",
    "pose_xyz = pose_xyz.reshape(1, -1, 22, 3)\n",
    "pose_xyz = pose_xyz / 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization.plot_3d_global as plot_3d\n",
    "pose_vis = plot_3d.draw_to_batch(pose_xyz.detach().cpu().numpy(), 'debug', ['./results/debug_recover_from_rot/3.gif'])\n",
    "pose_vis = plot_3d.draw_to_batch(xyz.detach().cpu().numpy(), 'debug', ['./results/debug_recover_from_rot/3_gt.gif'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
